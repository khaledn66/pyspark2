{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaledn66/pyspark2/blob/main/read_write_and_validate_data_hw_solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGddTwyDVsUu"
      },
      "source": [
        "# Reading, Writing and Validating Data in PySpark HW Solutions\n",
        "\n",
        "Welcome to your first coding homework assignment in PySpark! I hope you enjoyed the lecture on Reading, Writing and Validating dataframes. Now it's time to put what you've learned into action!\n",
        "\n",
        "I've included several instructions below to help guide you through this homework assignment which I hope will get you feeling even comfortable reading, writing and validating dataframes. If you get at any point, feel free to jump to the next lecture where I will guide you through my solutions to the HW assignment.\n",
        "\n",
        "Have fun!\n",
        "\n",
        "Let's dig right in!\n",
        "\n",
        "\n",
        "## But first things first.....\n",
        "We need to always begin every Spark session by creating a Spark instance. Let's go ahead and use the method we learned in the lecture in the cell below. Also see if you can remember how to open the Spark UI (using a link that automatically guides you there)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "OvsdGSZ2VsUx",
        "outputId": "d9707a4e-8af4-4ba9-f991-6550c82096b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are working with 1 core(s)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f3a0a4312a0>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://a0c812d74fe6:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>ReadWriteVal</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# import findspark\n",
        "# findspark.init()\n",
        "\n",
        "import pyspark # only run after findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "# May take awhile locally\n",
        "spark = SparkSession.builder.appName(\"ReadWriteVal\").getOrCreate()\n",
        "\n",
        "cores = spark._jsc.sc().getExecutorMemoryStatus().keySet().size()\n",
        "print(\"You are working with\", cores, \"core(s)\")\n",
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArDjzreEaMG0",
        "outputId": "d3fd2641-8ea6-4073-892c-baabab252d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBKnLQhoVsUy"
      },
      "source": [
        "## Next let's start by reading a basic csv dataset\n",
        "\n",
        "Download the pga_tour_data_historical dataset that is attached to this lecture and save it whatever folder you want, then read it in.\n",
        "\n",
        "**Data Source:** https://www.kaggle.com/bradklassen/pga-tour-20102018-data\n",
        "\n",
        "Rememer to try letting Spark infer the header and infer the Schema types!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lW_wzowmVsUz"
      },
      "outputs": [],
      "source": [
        "path =\"./drive/MyDrive/content/\"\n",
        "\n",
        "# Some csv data\n",
        "pga = spark.read.csv(path+'pga_tour_historical.csv',inferSchema=True,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d94eqdvEpcbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3q25N3txpefM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgSRaDJ0VsUz"
      },
      "source": [
        "## 1. View first 5 lines of dataframe\n",
        "First generate a view of the first 5 lines of the dataframe to get an idea of what is inside. We went over two ways of doing this... see if you can remember BOTH ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQrx6KvIVsUz",
        "outputId": "146c6c85-3c8b-41b9-d3f7-7387b93dc742"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------+------+----------------+--------------------+-----+\n",
            "|    Player Name|Season|       Statistic|            Variable|Value|\n",
            "+---------------+------+----------------+--------------------+-----+\n",
            "|Robert Garrigus|  2010|Driving Distance|Driving Distance ...|   71|\n",
            "|   Bubba Watson|  2010|Driving Distance|Driving Distance ...|   77|\n",
            "| Dustin Johnson|  2010|Driving Distance|Driving Distance ...|   83|\n",
            "+---------------+------+----------------+--------------------+-----+\n",
            "only showing top 3 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pga.show(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "9y6iACynVsUz",
        "outputId": "63bbb006-1d46-482c-d9c1-4c25779aed18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Player Name  Season         Statistic                     Variable  \\\n",
              "0  Robert Garrigus    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
              "1     Bubba Watson    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
              "2   Dustin Johnson    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
              "3  Brett Wetterich    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
              "4      J.B. Holmes    2010  Driving Distance  Driving Distance - (ROUNDS)   \n",
              "\n",
              "  Value  \n",
              "0    71  \n",
              "1    77  \n",
              "2    83  \n",
              "3    54  \n",
              "4   100  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-534c7454-8b33-42ae-8a87-32a68155122a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Player Name</th>\n",
              "      <th>Season</th>\n",
              "      <th>Statistic</th>\n",
              "      <th>Variable</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Robert Garrigus</td>\n",
              "      <td>2010</td>\n",
              "      <td>Driving Distance</td>\n",
              "      <td>Driving Distance - (ROUNDS)</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Bubba Watson</td>\n",
              "      <td>2010</td>\n",
              "      <td>Driving Distance</td>\n",
              "      <td>Driving Distance - (ROUNDS)</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dustin Johnson</td>\n",
              "      <td>2010</td>\n",
              "      <td>Driving Distance</td>\n",
              "      <td>Driving Distance - (ROUNDS)</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Brett Wetterich</td>\n",
              "      <td>2010</td>\n",
              "      <td>Driving Distance</td>\n",
              "      <td>Driving Distance - (ROUNDS)</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>J.B. Holmes</td>\n",
              "      <td>2010</td>\n",
              "      <td>Driving Distance</td>\n",
              "      <td>Driving Distance - (ROUNDS)</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-534c7454-8b33-42ae-8a87-32a68155122a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-534c7454-8b33-42ae-8a87-32a68155122a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-534c7454-8b33-42ae-8a87-32a68155122a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3a80388-7ff2-420e-aa99-3dd207b5acef\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3a80388-7ff2-420e-aa99-3dd207b5acef')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3a80388-7ff2-420e-aa99-3dd207b5acef button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pga\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Player Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Bubba Watson\",\n          \"J.B. Holmes\",\n          \"Dustin Johnson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Season\",\n      \"properties\": {\n        \"dtype\": \"int32\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          2010\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Statistic\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Driving Distance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Variable\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Driving Distance - (ROUNDS)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Value\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"77\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# I prefer this method\n",
        "pga.limit(5).toPandas()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCygw3SzVsU0"
      },
      "source": [
        "## 2. Print the schema details\n",
        "\n",
        "Now print the details of the dataframes schema that Spark infered to ensure that it was infered correctly. Sometimes it is not infered correctly, so we need to watch out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4icTLZoVsU0",
        "outputId": "2959ea3a-c0f5-453c-af28-ff034af9d34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Player Name: string (nullable = true)\n",
            " |-- Season: integer (nullable = true)\n",
            " |-- Statistic: string (nullable = true)\n",
            " |-- Variable: string (nullable = true)\n",
            " |-- Value: string (nullable = true)\n",
            "\n",
            "None\n",
            "\n",
            "['Player Name', 'Season', 'Statistic', 'Variable', 'Value']\n",
            "\n",
            "DataFrame[summary: string, Player Name: string, Season: string, Statistic: string, Variable: string, Value: string]\n"
          ]
        }
      ],
      "source": [
        "print(pga.printSchema())\n",
        "print(\"\")\n",
        "print(pga.columns)\n",
        "print(\"\")\n",
        "# Not so fond of this method, but to each their own\n",
        "print(pga.describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zQ0dP1OVsU0"
      },
      "source": [
        "## 3. Edit the schema during the read in\n",
        "\n",
        "We can see from the output above that Spark did not correctly infer that the \"value\" column was an integer value. Let's try specifying the schema this time to let spark know what the schema should be.\n",
        "\n",
        "Here is a link to see a list of PySpark data types in case you need it (also attached to the lecture): https://spark.apache.org/docs/latest/sql-reference.html#data-types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2AEijk1vVsU0"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import StructField,StringType,IntegerType,StructType"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iyeYGsXVsU1"
      },
      "outputs": [],
      "source": [
        "data_schema = [StructField(\"Player Name\", StringType(), True), \\\n",
        "               StructField(\"Season\", IntegerType(), True), \\\n",
        "               StructField(\"Statistic\", StringType(), True), \\\n",
        "               StructField(\"Variable\", StringType(), True), \\\n",
        "               StructField(\"Value\", IntegerType(), True)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogIlN6EBVsU1"
      },
      "outputs": [],
      "source": [
        "final_struc = StructType(fields=data_schema)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IE8cc4ImVsU1"
      },
      "outputs": [],
      "source": [
        "path =\"Datasets/\"\n",
        "pga = spark.read.csv(path+'pga_tour_historical.csv', schema=final_struc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzPIXnSgVsU1",
        "outputId": "a6ccbace-318d-4810-ac3e-3887022d2852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Player Name: string (nullable = true)\n",
            " |-- Season: integer (nullable = true)\n",
            " |-- Statistic: string (nullable = true)\n",
            " |-- Variable: string (nullable = true)\n",
            " |-- Value: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pga.printSchema()\n",
        "# That's better!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vliY8Xb0VsU1"
      },
      "source": [
        "## 4. Generate summary statistics for only one variable\n",
        "\n",
        "See if you can generate summary statistics for only the \"Value\" column using the .describe function\n",
        "\n",
        "(count, mean, stddev, min, max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zi27qOG_VsU1",
        "outputId": "e0e36f2c-d389-4f45-b14a-ee34d22d2f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+\n",
            "|summary|             Value|\n",
            "+-------+------------------+\n",
            "|  count|           1657247|\n",
            "|   mean|12494.388998743096|\n",
            "| stddev| 157274.7567357075|\n",
            "|    min|              -178|\n",
            "|    max|           3564954|\n",
            "+-------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Neat \"describe\" function\n",
        "pga.describe(['Value']).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SklCf1H3VsU2"
      },
      "source": [
        "## 5. Generate summary statistics for TWO variables\n",
        "Now try to generate ONLY the count min and max for BOTH the \"Value\" and \"Season\" variable using the select. You can't use the .describe function for this one but see if you can remember which function you CAN use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPrhm7qQVsU2",
        "outputId": "6f7d31a1-16ee-428e-fd8d-1944f389a988"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------+-------+\n",
            "|summary| Season|  Value|\n",
            "+-------+-------+-------+\n",
            "|  count|1700745|1657247|\n",
            "|    min|   2010|   -178|\n",
            "|    max|   2018|3564954|\n",
            "+-------+-------+-------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "pga.select(\"Season\", \"Value\").summary(\"count\", \"min\", \"max\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA_HpjDQVsU2"
      },
      "source": [
        "## 6. Write a parquet file\n",
        "\n",
        "Now try writing a parquet file (not partitioned) from the pga dataset. But first create a new dataframe containing ONLY the the \"Season\" and \"Value\" fields (using the \"select command you used in the question above) and write a parquet file partitioned by \"Season\". This is a bit of a challenge aimed at getting you ready for material that will be covered later on in the course. Don't feel bad if you can't figure it out.\n",
        "\n",
        "*Note that if any of your variable names contain spaces, spark will produce an error message with this call. That is why we are selecting ONLY the \"Season\" and \"Value\" fields. Ideally we should renamed those columns but we haven't gotten to that yet in this course but we will soon!*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ibWmbiHCVsU2"
      },
      "outputs": [],
      "source": [
        "df = pga.select(\"Season\",\"Value\")\n",
        "df.write.mode(\"overwrite\").parquet(\"partition_parquet/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZphYGrZVsU2"
      },
      "source": [
        "## 7. Write a partioned parquet file\n",
        "\n",
        "You will need to use the same limited dataframe that you created in the previous question to accomplish this task as well. Use the variable \"Season\" as you partitioning variable here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFMVOXVSVsU2",
        "outputId": "3b6697f7-3ef7-4308-9c18-03b40db5db3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Season|Value|\n",
            "+------+-----+\n",
            "|  2010|   71|\n",
            "|  2010|   77|\n",
            "|  2010|   83|\n",
            "|  2010|   54|\n",
            "|  2010|  100|\n",
            "|  2010|   63|\n",
            "|  2010|   88|\n",
            "|  2010|   64|\n",
            "|  2010|   64|\n",
            "|  2010|   92|\n",
            "|  2010|   75|\n",
            "|  2010|   54|\n",
            "|  2010|   76|\n",
            "|  2010|   94|\n",
            "|  2010|   82|\n",
            "|  2010|   85|\n",
            "|  2010|   79|\n",
            "|  2010|   89|\n",
            "|  2010|   88|\n",
            "|  2010|   91|\n",
            "+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.write.mode(\"overwrite\").partitionBy(\"Season\").parquet(\"partitioned_parquet/\")\n",
        "df.show(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PioyycA2VsU2"
      },
      "source": [
        "## 8. Read in a partitioned parquet file\n",
        "\n",
        "Now try reading in the partitioned parquet file you just created above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1FbzjcoVsU3",
        "outputId": "7c6d4c9c-93f8-46f5-9c02-b47c565b242f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+------+\n",
            "|Value|Season|\n",
            "+-----+------+\n",
            "|   71|  2010|\n",
            "|   77|  2010|\n",
            "|   83|  2010|\n",
            "|   54|  2010|\n",
            "|  100|  2010|\n",
            "|   63|  2010|\n",
            "|   88|  2010|\n",
            "|   64|  2010|\n",
            "|   64|  2010|\n",
            "|   92|  2010|\n",
            "|   75|  2010|\n",
            "|   54|  2010|\n",
            "|   76|  2010|\n",
            "|   94|  2010|\n",
            "|   82|  2010|\n",
            "|   85|  2010|\n",
            "|   79|  2010|\n",
            "|   89|  2010|\n",
            "|   88|  2010|\n",
            "|   91|  2010|\n",
            "+-----+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "path = \"partitioned_parquet/\" #Note: if you add a * to the end of the path, the Season var will be automatically dropped\n",
        "parquet = spark.read.parquet(path)\n",
        "\n",
        "parquet.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "from chat Gpt"
      ],
      "metadata": {
        "id": "JHTHAANbkxQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk('/content'):\n",
        "    for file in files:\n",
        "        if file == '/partitioned_parquet/':\n",
        "            print(os.path.join(root, file))"
      ],
      "metadata": {
        "id": "VPqwVT6je4Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B52UIbLSMnvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VzWeRmEfmyq",
        "outputId": "79e7936d-ca9e-4616-ad5d-92c99b8f6fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/partitioned_parquet/content/drive/MyDrive/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuLk9mn3hEcT",
        "outputId": "91775aa0-c00a-4e68-f1ed-e32fb117e08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: missing destination file operand after '/content/partitioned_parquet.parquet/content/drive/MyDrive/'\n",
            "Try 'cp --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1wV7FQLVsU3"
      },
      "source": [
        "## 9. Reading in a set of paritioned parquet files\n",
        "\n",
        "Now try only reading Seasons 2010, 2011 and 2012."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzf2DgnUVsU3",
        "outputId": "7b037c58-0ee9-4839-9c92-95da8b597f44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+\n",
            "|Value|\n",
            "+-----+\n",
            "|   79|\n",
            "|   82|\n",
            "|   93|\n",
            "|   74|\n",
            "|   85|\n",
            "+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Notice that this method only gives you the \"Value\" column\n",
        "path = \"partitioned_parquet/\"\n",
        "partitioned = spark.read.parquet(path+'Season=2010/',\\\n",
        "                             path+'Season=2011/', \\\n",
        "                             path+'Season=2012/')\n",
        "\n",
        "partitioned.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4M8SnxEVsU3",
        "outputId": "4daa3fb4-bfc0-4ff4-f904-fefdbeb58816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-----+------+\n",
            "|Value|Season|\n",
            "+-----+------+\n",
            "|   79|  2010|\n",
            "|   82|  2010|\n",
            "|   93|  2010|\n",
            "|   74|  2010|\n",
            "|   85|  2010|\n",
            "+-----+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We need to use this method to get the \"Season\" and \"Value\" Columns\n",
        "path = \"partitioned_parquet/\"\n",
        "dataframe = spark.read.option(\"basePath\", path).parquet(path+'Season=2010/',\\\n",
        "                                                                path+'Season=2011/', \\\n",
        "                                                                path+'Season=2012/')\n",
        "dataframe.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RInM8o9AVsU3"
      },
      "source": [
        "## 10. Create your own dataframe\n",
        "\n",
        "Try creating your own dataframe below using PySparks *.createDataFrame* function. See if you can make one that contains 4 variables and at least 3 rows.\n",
        "\n",
        "Let's see how creative you can get on the content of the dataframe :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4EKE3PWVsU3",
        "outputId": "94bd9304-4e8b-489a-921f-cc0e26a81bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---+---+------+\n",
            "|     name|age| AB|Number|\n",
            "+---------+---+---+------+\n",
            "|     Kyle| 10|  A|     1|\n",
            "|Melbourne| 36|  A|     1|\n",
            "|     Nina|123|  A|     1|\n",
            "|  Stephen| 48|  B|     2|\n",
            "|   Orphan| 16|  B|     2|\n",
            "|    Imran|  1|  B|     2|\n",
            "+---------+---+---+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "values = [('Kyle',10,'A',1),('Melbourne',36,'A',1),('Nina',123,'A',1),('Stephen',48,'B',2),('Orphan',16,'B',2),('Imran',1,'B',2)]\n",
        "df = spark.createDataFrame(values,['name','age','AB','Number'])\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cA6R9jNVsU3"
      },
      "source": [
        "## We're done! Great job!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}