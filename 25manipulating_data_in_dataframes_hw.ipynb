{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khaledn66/pyspark2/blob/main/25manipulating_data_in_dataframes_hw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQCmjEYI-EVg"
      },
      "source": [
        "# Manipulating Data in DataFrames HW\n",
        "\n",
        "\n",
        "#### Let's get started applying what we learned in the lecure!\n",
        "\n",
        "I've provided several questions below to help test and expand you knowledge from the code along lecture. So let's see what you've got!\n",
        "\n",
        "First create your spark instance as we need to do at the start of every project."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Hz9yqIWS-EVi",
        "outputId": "37278ddb-4f74-4049-abc5-1fbf963fa965"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7e57c8c92c50>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://ddfe512cfbfb:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>FirstSpark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.appName(\"FirstSpark\").getOrCreate()\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oVLscCM-EVi"
      },
      "source": [
        "## Read in our Republican vs. Democrats Tweet DataFrame\n",
        "\n",
        "Attached to the lecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Csrxwrie-EVj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNtW2nSZ-EVj"
      },
      "source": [
        "## About this dataframe\n",
        "\n",
        "Extracted tweets from all of the representatives (latest 200 as of May 17th 2018)\n",
        "\n",
        "**Source:** https://www.kaggle.com/kapastor/democratvsrepublicantweets#ExtractedTweets.csv\n",
        "\n",
        "Use either .show() or .toPandas() check out the first view rows of the dataframe to get an idea of what we are working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lni7x4IZ-EVj",
        "outputId": "1438b9cb-ee24-44d8-f3cc-f3d55c3af557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pyspark2'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Counting objects: 100% (53/53), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 53 (delta 22), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (53/53), 7.41 MiB | 5.47 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf pyspark2\n",
        "\n",
        "# Repository erneut klonen\n",
        "!git clone https://github.com/khaledn66/pyspark2.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNLXbjja-EVj"
      },
      "source": [
        "**Prevent Truncation of view**\n",
        "\n",
        "If the view you produced above truncated some of the longer tweets, see if you can prevent that so you can read the whole tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4bfyoS1-EVj",
        "outputId": "83de8825-89a2-4dfc-bf78-c009effb63c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-------------+--------------------+\n",
            "|               Party|       Handle|               Tweet|\n",
            "+--------------------+-------------+--------------------+\n",
            "|            Democrat|RepDarrenSoto|Today, Senate Dem...|\n",
            "|            Democrat|RepDarrenSoto|RT @WinterHavenSu...|\n",
            "|            Democrat|RepDarrenSoto|RT @NBCLatino: .@...|\n",
            "|Congress has allo...|         NULL|                NULL|\n",
            "|            Democrat|RepDarrenSoto|RT @NALCABPolicy:...|\n",
            "+--------------------+-------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = './pyspark2/Rep_vs_Dem_tweets.csv'\n",
        "tweets = spark.read.csv(file_path, inferSchema=True, header=True)\n",
        "tweets.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfd_pKTH-EVj"
      },
      "source": [
        "**Print Schema**\n",
        "\n",
        "First, check the schema to make sure the datatypes are accurate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtXUmv58-EVk",
        "outputId": "e560138d-5238-462b-fe6a-2680d3faa63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Party: string (nullable = true)\n",
            " |-- Handle: string (nullable = true)\n",
            " |-- Tweet: string (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(tweets.printSchema())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i06S4up-EVk"
      },
      "source": [
        "## 1. Can you identify any tweet that mentions the handle @LatinoLeader using regexp_extract?\n",
        "\n",
        "It doesn't matter how you identify the row, any identifier will do. You can test your script on row 5 from this dataset. That row contains @LatinoLeader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bf_eGwn_-EVk",
        "outputId": "6f38b194-1c86-440e-eb5c-cebd40183340"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Handle       |Tweet                                                                                                                                       |\n",
            "+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|RepDarrenSoto|RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|\n",
            "+-------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "tweets.select(\"Handle\",\"Tweet\").where(tweets.Tweet.like(\"%@LatinoLeader %\")).show(5, False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_replace, regexp_extract"
      ],
      "metadata": {
        "id": "ZuS5qOKX0hIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pattern = r\"(@LatinoLeader\\b)\"\n",
        "pattern = r\"\\b@LatinoLeader\\b\"\n",
        "\n",
        "# Verwende regexp_extract, um den exakten Wert zu extrahieren\n",
        "tweets = tweets.withColumn(\"Handle\", regexp_extract(tweets.Tweet, pattern, 0))\n",
        "\n",
        "# Zeige die Ergebnisse\n",
        "tweets.show(truncate=False)\n",
        "\n",
        "# Benutzernamen extrahieren\n",
        "tweets = tweets.withColumn(\"Handle\", regexp_extract(tweets.Handle, pattern, 1))\n",
        "\n",
        "tweets.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4AQikIV1_j-",
        "outputId": "c44c7b8c-02a0-4773-f220-3f3fe20f8679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Party                                               |Handle|Tweet                                                                                                                                       |\n",
            "+----------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Democrat                                            |      |Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House… https://t.co/n3tggDLU1L |\n",
            "|Democrat                                            |      |RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…|\n",
            "|Democrat                                            |      |RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
            "|Congress has allocated about $18…\"                  |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat                                            |      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|\n",
            "|Democrat                                            |      |RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico’s readiness...well 🤦🏼‍♂️😡😩@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
            "|Democrat                                            |      |RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without… |\n",
            "|Democrat                                            |      |Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr… https://t.co/2kU8BcKwUh|\n",
            "|Democrat                                            |      |RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out…|\n",
            "|Democrat                                            |      |RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can’t find Americans willing to do…|\n",
            "|Democrat                                            |      |RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid…|\n",
            "|Democrat                                            |      |RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr…|\n",
            "|Democrat                                            |      |.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty… https://t.co/jCrURA4oLz       |\n",
            "|Democrat                                            |      |Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a… https://t.co/MXES0r31VH                |\n",
            "|Democrat                                            |      |We paid our respects at Nat’l Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
            "|Sgt Sam Howard - Kissimmee… https://t.co/UzPxIVBMYW\"|NULL  |NULL                                                                                                                                        |\n",
            "|Democrat                                            |      |RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad…|\n",
            "|Democrat                                            |      |Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus… https://t.co/lND3zgvJ55             |\n",
            "|Democrat                                            |      |RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove…|\n",
            "|Democrat                                            |      |RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir…|\n",
            "+----------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+----------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Party                                               |Handle|Tweet                                                                                                                                       |\n",
            "+----------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Democrat                                            |      |Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House… https://t.co/n3tggDLU1L |\n",
            "|Democrat                                            |      |RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…|\n",
            "|Democrat                                            |      |RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
            "|Congress has allocated about $18…\"                  |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat                                            |      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|\n",
            "|Democrat                                            |      |RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico’s readiness...well 🤦🏼‍♂️😡😩@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
            "|Democrat                                            |      |RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without… |\n",
            "|Democrat                                            |      |Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr… https://t.co/2kU8BcKwUh|\n",
            "|Democrat                                            |      |RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out…|\n",
            "|Democrat                                            |      |RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can’t find Americans willing to do…|\n",
            "|Democrat                                            |      |RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid…|\n",
            "|Democrat                                            |      |RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr…|\n",
            "|Democrat                                            |      |.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty… https://t.co/jCrURA4oLz       |\n",
            "|Democrat                                            |      |Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a… https://t.co/MXES0r31VH                |\n",
            "|Democrat                                            |      |We paid our respects at Nat’l Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
            "|Sgt Sam Howard - Kissimmee… https://t.co/UzPxIVBMYW\"|NULL  |NULL                                                                                                                                        |\n",
            "|Democrat                                            |      |RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad…|\n",
            "|Democrat                                            |      |Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus… https://t.co/lND3zgvJ55             |\n",
            "|Democrat                                            |      |RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove…|\n",
            "|Democrat                                            |      |RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir…|\n",
            "+----------------------------------------------------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Tweets = tweets.withColumn('Handle',regexp_extract(tweets.Handle,  r\"\\b@LatinoLeader\\b\",1)).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztZnzO-bzmR9",
        "outputId": "495725c5-751f-4472-9374-486992abf7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------+--------------------+\n",
            "|               Party|Handle|               Tweet|\n",
            "+--------------------+------+--------------------+\n",
            "|            Democrat|      |Today, Senate Dem...|\n",
            "|            Democrat|      |RT @WinterHavenSu...|\n",
            "|            Democrat|      |RT @NBCLatino: .@...|\n",
            "|Congress has allo...|  NULL|                NULL|\n",
            "|            Democrat|      |RT @NALCABPolicy:...|\n",
            "|            Democrat|      |RT @Vegalteno: Hu...|\n",
            "|            Democrat|      |RT @EmgageActionF...|\n",
            "|            Democrat|      |Hurricane Maria l...|\n",
            "|            Democrat|      |RT @Tharryry: I a...|\n",
            "|            Democrat|      |RT @HispanicCaucu...|\n",
            "|            Democrat|      |RT @RepStephMurph...|\n",
            "|            Democrat|      |RT @AllSaints_FL:...|\n",
            "|            Democrat|      |.@realDonaldTrump...|\n",
            "|            Democrat|      |Thank you to my m...|\n",
            "|            Democrat|      |We paid our respe...|\n",
            "|Sgt Sam Howard - ...|  NULL|                NULL|\n",
            "|            Democrat|      |RT @WinterHavenSu...|\n",
            "|            Democrat|      |Meet 12 incredibl...|\n",
            "|            Democrat|      |RT @wildlifeactio...|\n",
            "|            Democrat|      |RT @CHeathWFTV: K...|\n",
            "+--------------------+------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Filter auf exakten Benutzernamen @LatinoLeader in der Tweet-Spalte\n",
        "tweets_filtered = tweets.filter(col(\"Tweet\").contains(\"@LatinoLeader\"))\n",
        "\n",
        "tweets_filtered.show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toM-t8xQDkGL",
        "outputId": "dd6925f3-8d81-4c45-b515-d5289b8b51b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Party   |Handle|Tweet                                                                                                                                       |\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Democrat|      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdYB2Fxf-EVk"
      },
      "source": [
        "## 2. Replace any value other than 'Democrate' or 'Republican' with 'Other' in the Party column.\n",
        "\n",
        "We can see from the output below, that there are several other values other than 'Democrate' or 'Republican' in the Part column. We are assuming that this is dirty data that needs to be cleaned up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATR4Ja9M-EVk",
        "outputId": "8b28fc0d-ac9a-4b5a-c9ce-b0e1575a3520"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Party   |Handle|Tweet                                                                                                                                       |\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Democrat|      |Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House… https://t.co/n3tggDLU1L |\n",
            "|Democrat|      |RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…|\n",
            "|Democrat|      |RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat|      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|\n",
            "|Democrat|      |RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico’s readiness...well 🤦🏼‍♂️😡😩@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
            "|Democrat|      |RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without… |\n",
            "|Democrat|      |Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr… https://t.co/2kU8BcKwUh|\n",
            "|Democrat|      |RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out…|\n",
            "|Democrat|      |RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can’t find Americans willing to do…|\n",
            "|Democrat|      |RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid…|\n",
            "|Democrat|      |RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr…|\n",
            "|Democrat|      |.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty… https://t.co/jCrURA4oLz       |\n",
            "|Democrat|      |Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a… https://t.co/MXES0r31VH                |\n",
            "|Democrat|      |We paid our respects at Nat’l Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat|      |RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad…|\n",
            "|Democrat|      |Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus… https://t.co/lND3zgvJ55             |\n",
            "|Democrat|      |RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove…|\n",
            "|Democrat|      |RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir…|\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "# Ersetzen von Werten in der 'Party' Spalte\n",
        "tweets = tweets.withColumn(\"Party\",\n",
        "                           when(col(\"Party\") == \"Democrat\", \"Democrat\")\n",
        "                           .when(col(\"Party\") == \"Republican\", \"Republican\")\n",
        "                           .otherwise(\"Other\"))\n",
        "\n",
        "tweets.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GFl-sNK-EVk"
      },
      "source": [
        "## 3. Delete all embedded links (ie. \"https:....)\n",
        "\n",
        "For example see the first row in the tweets dataframe.\n",
        "\n",
        "*Note: this may require an google search :)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfjYbOxN-EVk",
        "outputId": "acc55f15-1b30-47d5-ba24-a3a1d60c20c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Party   |Handle|Tweet                                                                                                                                       |\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Democrat|      |Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House…                         |\n",
            "|Democrat|      |RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…|\n",
            "|Democrat|      |RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat|      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|\n",
            "|Democrat|      |RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico’s readiness...well 🤦🏼‍♂️😡😩@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
            "|Democrat|      |RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without… |\n",
            "|Democrat|      |Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr…                        |\n",
            "|Democrat|      |RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out…|\n",
            "|Democrat|      |RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can’t find Americans willing to do…|\n",
            "|Democrat|      |RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid…|\n",
            "|Democrat|      |RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr…|\n",
            "|Democrat|      |.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty…                               |\n",
            "|Democrat|      |Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a…                                        |\n",
            "|Democrat|      |We paid our respects at Nat’l Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat|      |RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad…|\n",
            "|Democrat|      |Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus…                                     |\n",
            "|Democrat|      |RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove…|\n",
            "|Democrat|      |RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir…|\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import regexp_replace\n",
        "\n",
        "# Replace URLs starting with 'http://' or 'https://' with an empty string\n",
        "tweets = tweets.withColumn(\"Tweet\",\n",
        "                           regexp_replace(col(\"Tweet\"), r\"https?://\\S+\", \"\"))\n",
        "\n",
        "tweets.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzDF1dHy-EVk"
      },
      "source": [
        "## 4. Remove any leading or trailing white space in the tweet column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzaAHktZ-EVk",
        "outputId": "5257308c-7697-42c3-c3c0-19f81951cf64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Party   |Handle|Tweet                                                                                                                                       |\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Democrat|      |Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House…                         |\n",
            "|Democrat|      |RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…|\n",
            "|Democrat|      |RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat|      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|\n",
            "|Democrat|      |RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico’s readiness...well 🤦🏼‍♂️😡😩@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
            "|Democrat|      |RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without… |\n",
            "|Democrat|      |Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr…                        |\n",
            "|Democrat|      |RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out…|\n",
            "|Democrat|      |RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can’t find Americans willing to do…|\n",
            "|Democrat|      |RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid…|\n",
            "|Democrat|      |RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr…|\n",
            "|Democrat|      |.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty…                               |\n",
            "|Democrat|      |Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a…                                        |\n",
            "|Democrat|      |We paid our respects at Nat’l Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat|      |RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad…|\n",
            "|Democrat|      |Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus…                                     |\n",
            "|Democrat|      |RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove…|\n",
            "|Democrat|      |RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir…|\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import trim, col\n",
        "\n",
        "# Remove leading and trailing white spaces in the 'Tweet' column\n",
        "tweets = tweets.withColumn(\"Tweet\", trim(col(\"Tweet\")))\n",
        "\n",
        "tweets.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkt1YASK-EVl"
      },
      "source": [
        "## 5. Rename the 'Party' column to 'Dem_Rep'\n",
        "\n",
        "No real reason here :) just wanted you to get practice doing this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiZhkWIz-EVl",
        "outputId": "c5e3980b-f3e8-49d2-b65b-53edf7e68901"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Dem_Rep |Handle|Tweet                                                                                                                                       |\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "|Democrat|      |Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House…                         |\n",
            "|Democrat|      |RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…|\n",
            "|Democrat|      |RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat|      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|\n",
            "|Democrat|      |RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico’s readiness...well 🤦🏼‍♂️😡😩@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |\n",
            "|Democrat|      |RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without… |\n",
            "|Democrat|      |Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr…                        |\n",
            "|Democrat|      |RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out…|\n",
            "|Democrat|      |RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can’t find Americans willing to do…|\n",
            "|Democrat|      |RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid…|\n",
            "|Democrat|      |RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr…|\n",
            "|Democrat|      |.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty…                               |\n",
            "|Democrat|      |Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a…                                        |\n",
            "|Democrat|      |We paid our respects at Nat’l Law Enforcement Officers Memorial today for those we lost:                                                    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |\n",
            "|Democrat|      |RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad…|\n",
            "|Democrat|      |Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus…                                     |\n",
            "|Democrat|      |RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove…|\n",
            "|Democrat|      |RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir…|\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Rename the 'Party' column to 'Dem_Rep'\n",
        "tweets = tweets.withColumnRenamed(\"Party\", \"Dem_Rep\")\n",
        "\n",
        "tweets.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npkVX9Ef-EVl"
      },
      "source": [
        "## 6. Concatenate the Party and Handle columns\n",
        "\n",
        "Silly yes... but good practice.\n",
        "\n",
        "pyspark.sql.functions.concat_ws(sep, *cols)[source] <br>\n",
        "Concatenates multiple input string columns together into a single string column, using the given separator."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m268XbVT-EVl",
        "outputId": "15737062-54a9-4788-d9a7-b0123cba3000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+------------+\n",
            "|Dem_Rep |Handle|Tweet                                                                                                                                       |Party_Handle|\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+------------+\n",
            "|Democrat|      |Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House…                         |Democrat    |\n",
            "|Democrat|      |RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…|Democrat    |\n",
            "|Democrat|      |RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |Democrat    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |NULL        |\n",
            "|Democrat|      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|Democrat    |\n",
            "|Democrat|      |RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico’s readiness...well 🤦🏼‍♂️😡😩@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |Democrat    |\n",
            "|Democrat|      |RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without… |Democrat    |\n",
            "|Democrat|      |Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr…                        |Democrat    |\n",
            "|Democrat|      |RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out…|Democrat    |\n",
            "|Democrat|      |RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can’t find Americans willing to do…|Democrat    |\n",
            "|Democrat|      |RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid…|Democrat    |\n",
            "|Democrat|      |RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr…|Democrat    |\n",
            "|Democrat|      |.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty…                               |Democrat    |\n",
            "|Democrat|      |Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a…                                        |Democrat    |\n",
            "|Democrat|      |We paid our respects at Nat’l Law Enforcement Officers Memorial today for those we lost:                                                    |Democrat    |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |NULL        |\n",
            "|Democrat|      |RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad…|Democrat    |\n",
            "|Democrat|      |Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus…                                     |Democrat    |\n",
            "|Democrat|      |RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove…|Democrat    |\n",
            "|Democrat|      |RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir…|Democrat    |\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import concat, col\n",
        "\n",
        "# Concatenate 'Party' and 'Handle' columns\n",
        "tweets = tweets.withColumn(\"Party_Handle\", concat(col(\"Dem_Rep\"), col(\"Handle\")))\n",
        "\n",
        "tweets.show(truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OdoCI_C-EVl"
      },
      "source": [
        "## Challenge Question\n",
        "\n",
        "Let's image that we want to analyze the hashtags that are used in these tweets. Can you extract all the hashtags you see?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T5sNVcVO-EVl",
        "outputId": "c3096941-2a0c-4840-947b-0fa1ca2aa0f3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `#\\w+` cannot be resolved. Did you mean one of the following? [`Tweet`, `Handle`, `Dem_Rep`, `Party_Handle`].;\n'Project [Dem_Rep#499, Handle#404, Tweet#480, Party_Handle#518, regexp_extract_all(Tweet#480, '#\\w+, 1) AS Hashtags#544]\n+- Project [Dem_Rep#499, Handle#404, Tweet#480, concat(Dem_Rep#499, Handle#404) AS Party_Handle#518]\n   +- Project [Party#442 AS Dem_Rep#499, Handle#404, Tweet#480]\n      +- Project [Party#442, Handle#404, trim(Tweet#461, None) AS Tweet#480]\n         +- Project [Party#442, Handle#404, regexp_replace(Tweet#19, https?://\\S+, , 1) AS Tweet#461]\n            +- Project [CASE WHEN (Party#17 = Democrat) THEN Democrat WHEN (Party#17 = Republican) THEN Republican ELSE Other END AS Party#442, Handle#404, Tweet#19]\n               +- Project [Party#17, regexp_extract(Handle#385, \\b@LatinoLeader\\b, 1) AS Handle#404, Tweet#19]\n                  +- Project [Party#17, regexp_extract(Tweet#19, \\b@LatinoLeader\\b, 0) AS Handle#385, Tweet#19]\n                     +- Project [Party#17, regexp_extract(Handle#347, \\b@LatinoLeader\\b, 1) AS Handle#366, Tweet#19]\n                        +- Project [Party#17, regexp_extract(Tweet#19, \\b@LatinoLeader\\b, 0) AS Handle#347, Tweet#19]\n                           +- Project [Party#17, regexp_extract(Handle#309, \\b@LatinoLeader\\b, 1) AS Handle#328, Tweet#19]\n                              +- Project [Party#17, regexp_extract(Tweet#19, \\b@LatinoLeader\\b, 0) AS Handle#309, Tweet#19]\n                                 +- Project [Party#17, regexp_extract(Handle#271, (^|\\s)@LatinoLeader(\\s|$), 1) AS Handle#290, Tweet#19]\n                                    +- Project [Party#17, regexp_extract(Tweet#19, (^|\\s)@LatinoLeader(\\s|$), 0) AS Handle#271, Tweet#19]\n                                       +- Project [Party#17, regexp_extract(Handle#215, (@LatinoLeader\\b), 1) AS Handle#235, Tweet#19]\n                                          +- Project [Party#17, regexp_extract(Handle#171, (@LatinoLeader/b), 1) AS Handle#215, Tweet#19]\n                                             +- Project [Party#17, regexp_extract(Handle#151, (@LatinoLeader), 1) AS Handle#171, Tweet#19]\n                                                +- Project [Party#17, regexp_extract(Handle#131, (@LatinoLeader), 1) AS Handle#151, Tweet#19]\n                                                   +- Project [Party#17, regexp_extract(Handle#111, (@\\w+), 1) AS Handle#131, Tweet#19]\n                                                      +- Project [Party#17, regexp_extract(Handle#107, (@\\w+), 1) AS Handle#111, Tweet#19]\n                                                         +- Project [Party#17, regexp_extract(Handle#18, (@\\w+), 1) AS Handle#107, Tweet#19]\n                                                            +- Relation [Party#17,Handle#18,Tweet#19] csv\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-c43242a6a867>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Extract all hashtags in each tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hashtags\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregexp_extract_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tweet\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mwithColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   5174\u001b[0m                 \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"arg_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"col\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"arg_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5175\u001b[0m             )\n\u001b[0;32m-> 5176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparkSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexisting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `#\\w+` cannot be resolved. Did you mean one of the following? [`Tweet`, `Handle`, `Dem_Rep`, `Party_Handle`].;\n'Project [Dem_Rep#499, Handle#404, Tweet#480, Party_Handle#518, regexp_extract_all(Tweet#480, '#\\w+, 1) AS Hashtags#544]\n+- Project [Dem_Rep#499, Handle#404, Tweet#480, concat(Dem_Rep#499, Handle#404) AS Party_Handle#518]\n   +- Project [Party#442 AS Dem_Rep#499, Handle#404, Tweet#480]\n      +- Project [Party#442, Handle#404, trim(Tweet#461, None) AS Tweet#480]\n         +- Project [Party#442, Handle#404, regexp_replace(Tweet#19, https?://\\S+, , 1) AS Tweet#461]\n            +- Project [CASE WHEN (Party#17 = Democrat) THEN Democrat WHEN (Party#17 = Republican) THEN Republican ELSE Other END AS Party#442, Handle#404, Tweet#19]\n               +- Project [Party#17, regexp_extract(Handle#385, \\b@LatinoLeader\\b, 1) AS Handle#404, Tweet#19]\n                  +- Project [Party#17, regexp_extract(Tweet#19, \\b@LatinoLeader\\b, 0) AS Handle#385, Tweet#19]\n                     +- Project [Party#17, regexp_extract(Handle#347, \\b@LatinoLeader\\b, 1) AS Handle#366, Tweet#19]\n                        +- Project [Party#17, regexp_extract(Tweet#19, \\b@LatinoLeader\\b, 0) AS Handle#347, Tweet#19]\n                           +- Project [Party#17, regexp_extract(Handle#309, \\b@LatinoLeader\\b, 1) AS Handle#328, Tweet#19]\n                              +- Project [Party#17, regexp_extract(Tweet#19, \\b@LatinoLeader\\b, 0) AS Handle#309, Tweet#19]\n                                 +- Project [Party#17, regexp_extract(Handle#271, (^|\\s)@LatinoLeader(\\s|$), 1) AS Handle#290, Tweet#19]\n                                    +- Project [Party#17, regexp_extract(Tweet#19, (^|\\s)@LatinoLeader(\\s|$), 0) AS Handle#271, Tweet#19]\n                                       +- Project [Party#17, regexp_extract(Handle#215, (@LatinoLeader\\b), 1) AS Handle#235, Tweet#19]\n                                          +- Project [Party#17, regexp_extract(Handle#171, (@LatinoLeader/b), 1) AS Handle#215, Tweet#19]\n                                             +- Project [Party#17, regexp_extract(Handle#151, (@LatinoLeader), 1) AS Handle#171, Tweet#19]\n                                                +- Project [Party#17, regexp_extract(Handle#131, (@LatinoLeader), 1) AS Handle#151, Tweet#19]\n                                                   +- Project [Party#17, regexp_extract(Handle#111, (@\\w+), 1) AS Handle#131, Tweet#19]\n                                                      +- Project [Party#17, regexp_extract(Handle#107, (@\\w+), 1) AS Handle#111, Tweet#19]\n                                                         +- Project [Party#17, regexp_extract(Handle#18, (@\\w+), 1) AS Handle#107, Tweet#19]\n                                                            +- Relation [Party#17,Handle#18,Tweet#19] csv\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import regexp_extract_all, col\n",
        "\n",
        "# Regular expression to match hashtags (starting with # followed by alphanumeric characters)\n",
        "pattern = r\"#\\w+\"\n",
        "\n",
        "# Extract all hashtags in each tweet\n",
        "tweets = tweets.withColumn(\"Hashtags\", regexp_extract_all(col(\"Tweet\"), pattern))\n",
        "\n",
        "tweets.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_extract, col, explode, split\n",
        "\n",
        "# Regular expression to match hashtags\n",
        "pattern = r\"#\\w+\"\n",
        "\n",
        "# Extract hashtags and split them into an array of hashtags\n",
        "tweets = tweets.withColumn(\"Hashtags\", regexp_extract(col(\"Tweet\"), pattern, 0))\n",
        "\n",
        "# Alternatively, split by space to extract multiple hashtags (if more than one per tweet)\n",
        "tweets = tweets.withColumn(\"Hashtags\", split(col(\"Tweet\"), \" \"))\n",
        "\n",
        "# Filter to keep only the hashtags (those that start with #)\n",
        "tweets = tweets.withColumn(\"Hashtags\",\n",
        "                           explode(\n",
        "                               filter(lambda x: x.startswith(\"#\"), col(\"Hashtags\"))\n",
        "                           ))\n",
        "\n",
        "tweets.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "xbbCK_E2LBi9",
        "outputId": "46ce4bba-9016-4fd6-ff81-8d391d227c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "PySparkTypeError",
          "evalue": "[NOT_ITERABLE] Column is not iterable.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPySparkTypeError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-f1508557cde6>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m tweets = tweets.withColumn(\"Hashtags\", \n\u001b[1;32m     14\u001b[0m                            explode(\n\u001b[0;32m---> 15\u001b[0;31m                                \u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hashtags\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                            ))\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyspark/sql/column.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         raise PySparkTypeError(\n\u001b[0m\u001b[1;32m    719\u001b[0m             \u001b[0merror_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"NOT_ITERABLE\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"objectName\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Column\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m         )\n",
            "\u001b[0;31mPySparkTypeError\u001b[0m: [NOT_ITERABLE] Column is not iterable."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import regexp_extract, col, split, array\n",
        "\n",
        "# Regular expression to match hashtags (words starting with #)\n",
        "pattern = r\"#\\w+\"\n",
        "\n",
        "# Extract hashtags by splitting the text into words\n",
        "tweets = tweets.withColumn(\"Hashtags\", split(col(\"Tweet\"), \" \"))\n",
        "\n",
        "# Filter out non-hashtag words\n",
        "tweets = tweets.withColumn(\"Hashtags\",\n",
        "                           array(*[col(\"Hashtags\")[i] for i in range(0, 10)]))  # We select only first 10 for example\n",
        "\n",
        "tweets.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h3gfBLgLS0Q",
        "outputId": "fe0f4bd1-36b7-44e4-cf07-63fd53febf14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------+\n",
            "|Dem_Rep |Handle|Tweet                                                                                                                                       |Party_Handle|Hashtags                                                                                          |\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------+\n",
            "|Democrat|      |Today, Senate Dems vote to #SaveTheInternet. Proud to support similar #NetNeutrality legislation here in the House…                         |Democrat    |[Today,, Senate, Dems, vote, to, #SaveTheInternet., Proud, to, support, similar]                  |\n",
            "|Democrat|      |RT @WinterHavenSun: Winter Haven resident / Alta Vista teacher is one of several recognized by @RepDarrenSoto for National Teacher Apprecia…|Democrat    |[RT, @WinterHavenSun:, Winter, Haven, resident, /, Alta, Vista, teacher, is]                      |\n",
            "|Democrat|      |RT @NBCLatino: .@RepDarrenSoto noted that Hurricane Maria has left approximately $90 billion in damages.                                    |Democrat    |[RT, @NBCLatino:, .@RepDarrenSoto, noted, that, Hurricane, Maria, has, left, approximately]       |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |NULL        |[NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL]                                      |\n",
            "|Democrat|      |RT @NALCABPolicy: Meeting with @RepDarrenSoto . Thanks for taking the time to meet with @LatinoLeader ED Marucci Guzman. #NALCABPolicy2018.…|Democrat    |[RT, @NALCABPolicy:, Meeting, with, @RepDarrenSoto, ., Thanks, for, taking, the]                  |\n",
            "|Democrat|      |RT @Vegalteno: Hurricane season starts on June 1st; Puerto Rico’s readiness...well 🤦🏼‍♂️😡😩@Pwr4PuertoRico @RepDarrenSoto @EspaillatNY   |Democrat    |[RT, @Vegalteno:, Hurricane, season, starts, on, June, 1st;, Puerto, Rico’s]                      |\n",
            "|Democrat|      |RT @EmgageActionFL: Thank you to all who came out to our Orlando gala! It was a successful night that would not have been possible without… |Democrat    |[RT, @EmgageActionFL:, Thank, you, to, all, who, came, out, to]                                   |\n",
            "|Democrat|      |Hurricane Maria left approx $90 billion in damages, yet only $1 billion was allocated for rebuilding grid. No surpr…                        |Democrat    |[Hurricane, Maria, left, approx, $90, billion, in, damages,, yet, only]                           |\n",
            "|Democrat|      |RT @Tharryry: I am delighted that @RepDarrenSoto will be voting for the CRA to overrule the FCC and save our #NetNeutrality rules. Find out…|Democrat    |[RT, @Tharryry:, I, am, delighted, that, @RepDarrenSoto, will, be, voting]                        |\n",
            "|Democrat|      |RT @HispanicCaucus: Trump's anti-immigrant policies are hurting small businesses across the country that can’t find Americans willing to do…|Democrat    |[RT, @HispanicCaucus:, Trump's, anti-immigrant, policies, are, hurting, small, businesses, across]|\n",
            "|Democrat|      |RT @RepStephMurphy: Great joining @WeAreUnidosUS and @RepDarrenSoto for a roundtable in #Orlando on federal issues affecting central Florid…|Democrat    |[RT, @RepStephMurphy:, Great, joining, @WeAreUnidosUS, and, @RepDarrenSoto, for, a, roundtable]   |\n",
            "|Democrat|      |RT @AllSaints_FL: Zhihan (John)'s art received awards at this year's state competitions. We just found out he's won the Congressional Distr…|Democrat    |[RT, @AllSaints_FL:, Zhihan, (John)'s, art, received, awards, at, this, year's]                   |\n",
            "|Democrat|      |.@realDonaldTrump official policy to separate immigrant children from their mothers is definition of cruelty…                               |Democrat    |[.@realDonaldTrump, official, policy, to, separate, immigrant, children, from, their, mothers]    |\n",
            "|Democrat|      |Thank you to my mom Jean and all the mothers across this nation! You are raising our future. Have a…                                        |Democrat    |[Thank, you, to, my, mom, Jean, and, all, the, mothers]                                           |\n",
            "|Democrat|      |We paid our respects at Nat’l Law Enforcement Officers Memorial today for those we lost:                                                    |Democrat    |[We, paid, our, respects, at, Nat’l, Law, Enforcement, Officers, Memorial]                        |\n",
            "|Other   |NULL  |NULL                                                                                                                                        |NULL        |[NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL, NULL]                                      |\n",
            "|Democrat|      |RT @WinterHavenSun: Congratulations to  @AHSbloodhounds senior Abygayle Rausch for starting her service to the country at the US Naval Acad…|Democrat    |[RT, @WinterHavenSun:, Congratulations, to, , @AHSbloodhounds, senior, Abygayle, Rausch, for]     |\n",
            "|Democrat|      |Meet 12 incredible young leaders appointed to US Military Academies from our District! @HispanicCaucus…                                     |Democrat    |[Meet, 12, incredible, young, leaders, appointed, to, US, Military, Academies]                    |\n",
            "|Democrat|      |RT @wildlifeaction: With 1/3 of US wildlife in decline, Florida species like the snowy plover need advocates! As co-sponsors for the Recove…|Democrat    |[RT, @wildlifeaction:, With, 1/3, of, US, wildlife, in, decline,, Florida]                        |\n",
            "|Democrat|      |RT @CHeathWFTV: Keeping guns out of the wrong hands: following @WFTV report, @RepDarrenSoto asks ATF to look into so-called ghost guns (fir…|Democrat    |[RT, @CHeathWFTV:, Keeping, guns, out, of, the, wrong, hands:, following]                         |\n",
            "+--------+------+--------------------------------------------------------------------------------------------------------------------------------------------+------------+--------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ3jiDwN-EVl"
      },
      "source": [
        "# Let's create our own dataset to work with real dates\n",
        "\n",
        "This is a dataset of patient visits from a medical office. It contains the patients first and last names, date of birth, and the dates of their first 3 visits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpCAht9d-EVl",
        "outputId": "aafebf82-555a-4b57-f23c-8928571b1d10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+--------+---------+---------+\n",
            "|first_name|last_name|       dob|  visit1|   visit2|   visit3|\n",
            "+----------+---------+----------+--------+---------+---------+\n",
            "|  Mohammed|   Alfasy|  1987-4-8|2016-1-7| 2017-2-3| 2018-3-2|\n",
            "|     Marcy|Wellmaker|  1986-4-8|2015-1-7| 2017-1-3| 2018-1-2|\n",
            "|     Ginny|   Ginger| 1986-7-10|2014-8-7| 2015-2-3| 2016-3-2|\n",
            "|     Vijay| Doberson|  1988-5-2|2016-1-7| 2018-2-3| 2018-3-2|\n",
            "|     Orhan|  Gelicek| 1987-5-11|2016-5-7| 2017-1-3| 2018-9-2|\n",
            "|     Sarah|    Jones|  1956-7-6|2016-4-7| 2017-8-3|2018-10-2|\n",
            "|      John|  Johnson|2017-10-12|2018-1-2|2018-10-3| 2018-3-2|\n",
            "+----------+---------+----------+--------+---------+---------+\n",
            "\n",
            "root\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- last_name: string (nullable = true)\n",
            " |-- dob: string (nullable = true)\n",
            " |-- visit1: string (nullable = true)\n",
            " |-- visit2: string (nullable = true)\n",
            " |-- visit3: string (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.types import *\n",
        "\n",
        "md_office = [('Mohammed','Alfasy','1987-4-8','2016-1-7','2017-2-3','2018-3-2') \\\n",
        "            ,('Marcy','Wellmaker','1986-4-8','2015-1-7','2017-1-3','2018-1-2') \\\n",
        "            ,('Ginny','Ginger','1986-7-10','2014-8-7','2015-2-3','2016-3-2') \\\n",
        "            ,('Vijay','Doberson','1988-5-2','2016-1-7','2018-2-3','2018-3-2') \\\n",
        "            ,('Orhan','Gelicek','1987-5-11','2016-5-7','2017-1-3','2018-9-2') \\\n",
        "            ,('Sarah','Jones','1956-7-6','2016-4-7','2017-8-3','2018-10-2') \\\n",
        "            ,('John','Johnson','2017-10-12','2018-1-2','2018-10-3','2018-3-2') ]\n",
        "\n",
        "df = spark.createDataFrame(md_office,['first_name','last_name','dob','visit1','visit2','visit3']) # schema=final_struc\n",
        "\n",
        "# Check to make sure it worked\n",
        "df.show()\n",
        "print(df.printSchema())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M76T9W5r-EVm"
      },
      "source": [
        "Oh no! The dates are still stored as text... let's try converting them again and see if we have any issues this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-R-Na03-EVm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZUmLDYC-EVm"
      },
      "source": [
        "## 7. Can you calculate a variable showing the length of time between patient visits?\n",
        "\n",
        "Compare visit1 to visit2 and visit2 to visit3 for all patients and see what the average length of time is between visits. Create an alias for it as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "OS5hjPiF-EVm",
        "outputId": "d717f5d3-d595-4189-e6cf-a604d6aeb24a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'withColumn'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-b6952bb9cfc0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Calculate the time difference between visit1 and visit2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m md_office = md_office.withColumn(\"time_visit1_to_visit2\", \n\u001b[0m\u001b[1;32m      5\u001b[0m                            F.datediff(col(\"visit2\"), col(\"visit1\")))\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'withColumn'"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calculate the time difference between visit1 and visit2\n",
        "md_office = md_office.withColumn(\"time_visit1_to_visit2\",\n",
        "                           F.datediff(col(\"visit2\"), col(\"visit1\")))\n",
        "\n",
        "# Calculate the time difference between visit2 and visit3\n",
        "md_office = md_office.withColumn(\"time_visit2_to_visit3\",\n",
        "                           F.datediff(col(\"visit3\"), col(\"visit2\")))\n",
        "\n",
        "# Calculate the average time difference for all patients\n",
        "average_time_visit1_to_visit2 = md_office.agg(F.avg(\"time_visit1_to_visit2\")).collect()[0][0]\n",
        "average_time_visit2_to_visit3 = md_office.agg(F.avg(\"time_visit2_to_visit3\")).collect()[0][0]\n",
        "\n",
        "# Show the DataFrame with the calculated time differences\n",
        "md_office.show(truncate=False)\n",
        "\n",
        "# Output the average times between visits\n",
        "print(f\"Average time between visit1 and visit2: {average_time_visit1_to_visit2} days\")\n",
        "print(f\"Average time between visit2 and visit3: {average_time_visit2_to_visit3} days\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DateType\n",
        "\n",
        "# Your list of data\n",
        "md_office = [\n",
        "    ('Mohammed', 'Alfasy', '1987-4-8', '2016-1-7', '2017-2-3', '2018-3-2'),\n",
        "    ('Marcy', 'Wellmaker', '1986-4-8', '2015-1-7', '2017-1-3', '2018-1-2'),\n",
        "    ('Ginny', 'Ginger', '1986-7-10', '2014-8-7', '2015-2-3', '2016-3-2'),\n",
        "    ('Vijay', 'Doberson', '1988-5-2', '2016-1-7', '2018-2-3', '2018-3-2'),\n",
        "    ('Orhan', 'Gelicek', '1987-5-11', '2016-5-7', '2017-1-3', '2018-9-2'),\n",
        "    ('Sarah', 'Jones', '1956-7-6', '2016-4-7', '2017-8-3', '2018-10-2'),\n",
        "    ('John', 'Johnson', '2017-10-12', '2018-1-2', '2018-10-3', '2018-3-2')\n",
        "]\n",
        "\n",
        "# Define the schema for the DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"first_name\", StringType(), True),\n",
        "    StructField(\"last_name\", StringType(), True),\n",
        "    StructField(\"dob\", StringType(), True),\n",
        "    StructField(\"visit1\", StringType(), True),\n",
        "    StructField(\"visit2\", StringType(), True),\n",
        "    StructField(\"visit3\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Create a DataFrame from the list and schema\n",
        "df = spark.createDataFrame(md_office, schema)\n",
        "\n",
        "# Convert the date columns to DateType\n",
        "df = df.withColumn(\"dob\", F.to_date(\"dob\", \"yyyy-M-d\"))\n",
        "df = df.withColumn(\"visit1\", F.to_date(\"visit1\", \"yyyy-M-d\"))\n",
        "df = df.withColumn(\"visit2\", F.to_date(\"visit2\", \"yyyy-M-d\"))\n",
        "df = df.withColumn(\"visit3\", F.to_date(\"visit3\", \"yyyy-M-d\"))\n",
        "\n",
        "# Calculate the time difference between visit1 and visit2\n",
        "df = df.withColumn(\"time_visit1_to_visit2\", F.datediff(\"visit2\", \"visit1\"))\n",
        "\n",
        "# Calculate the time difference between visit2 and visit3\n",
        "df = df.withColumn(\"time_visit2_to_visit3\", F.datediff(\"visit3\", \"visit2\"))\n",
        "\n",
        "# Show the updated DataFrame\n",
        "df.show(truncate=False)\n",
        "\n",
        "# Check the schema to verify the column types\n",
        "df.printSchema()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSlvDhEdPRLc",
        "outputId": "505609e5-d199-4d20-aca2-bf8b4c4df254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+\n",
            "|first_name|last_name|dob       |visit1    |visit2    |visit3    |time_visit1_to_visit2|time_visit2_to_visit3|\n",
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+\n",
            "|Mohammed  |Alfasy   |1987-04-08|2016-01-07|2017-02-03|2018-03-02|393                  |392                  |\n",
            "|Marcy     |Wellmaker|1986-04-08|2015-01-07|2017-01-03|2018-01-02|727                  |364                  |\n",
            "|Ginny     |Ginger   |1986-07-10|2014-08-07|2015-02-03|2016-03-02|180                  |393                  |\n",
            "|Vijay     |Doberson |1988-05-02|2016-01-07|2018-02-03|2018-03-02|758                  |27                   |\n",
            "|Orhan     |Gelicek  |1987-05-11|2016-05-07|2017-01-03|2018-09-02|241                  |607                  |\n",
            "|Sarah     |Jones    |1956-07-06|2016-04-07|2017-08-03|2018-10-02|483                  |425                  |\n",
            "|John      |Johnson  |2017-10-12|2018-01-02|2018-10-03|2018-03-02|274                  |-215                 |\n",
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+\n",
            "\n",
            "root\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- last_name: string (nullable = true)\n",
            " |-- dob: date (nullable = true)\n",
            " |-- visit1: date (nullable = true)\n",
            " |-- visit2: date (nullable = true)\n",
            " |-- visit3: date (nullable = true)\n",
            " |-- time_visit1_to_visit2: integer (nullable = true)\n",
            " |-- time_visit2_to_visit3: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p70B0nyuPaQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calculate the time difference between visit1 and visit2\n",
        "df = df.withColumn(\"time_visit1_to_visit2\",\n",
        "                           F.datediff(col(\"visit2\"), col(\"visit1\")))\n",
        "\n",
        "# Calculate the time difference between visit2 and visit3\n",
        "df = df.withColumn(\"time_visit2_to_visit3\",\n",
        "                           F.datediff(col(\"visit3\"), col(\"visit2\")))\n",
        "\n",
        "# Calculate the average time difference for all patients\n",
        "average_time_visit1_to_visit2 = df.agg(F.avg(\"time_visit1_to_visit2\")).collect()[0][0]\n",
        "average_time_visit2_to_visit3 = df.agg(F.avg(\"time_visit2_to_visit3\")).collect()[0][0]\n",
        "\n",
        "# Show the DataFrame with the calculated time differences\n",
        "df.show(truncate=False)\n",
        "\n",
        "# Output the average times between visits\n",
        "print(f\"Average time between visit1 and visit2: {average_time_visit1_to_visit2} days\")\n",
        "print(f\"Average time between visit2 and visit3: {average_time_visit2_to_visit3} days\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "undEVW3jPioe",
        "outputId": "e1a3981e-a6a1-4c50-94a8-fe82f2f99fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+\n",
            "|first_name|last_name|dob       |visit1    |visit2    |visit3    |time_visit1_to_visit2|time_visit2_to_visit3|\n",
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+\n",
            "|Mohammed  |Alfasy   |1987-04-08|2016-01-07|2017-02-03|2018-03-02|393                  |392                  |\n",
            "|Marcy     |Wellmaker|1986-04-08|2015-01-07|2017-01-03|2018-01-02|727                  |364                  |\n",
            "|Ginny     |Ginger   |1986-07-10|2014-08-07|2015-02-03|2016-03-02|180                  |393                  |\n",
            "|Vijay     |Doberson |1988-05-02|2016-01-07|2018-02-03|2018-03-02|758                  |27                   |\n",
            "|Orhan     |Gelicek  |1987-05-11|2016-05-07|2017-01-03|2018-09-02|241                  |607                  |\n",
            "|Sarah     |Jones    |1956-07-06|2016-04-07|2017-08-03|2018-10-02|483                  |425                  |\n",
            "|John      |Johnson  |2017-10-12|2018-01-02|2018-10-03|2018-03-02|274                  |-215                 |\n",
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+\n",
            "\n",
            "Average time between visit1 and visit2: 436.57142857142856 days\n",
            "Average time between visit2 and visit3: 284.7142857142857 days\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apoquOJ--EVm"
      },
      "source": [
        "## 8. Can you calculate the age of each patient?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dsw7dsfr-EVn",
        "outputId": "80c71b9b-f0ad-4489-d93a-bea2c4324dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+---+\n",
            "|first_name|last_name|dob       |visit1    |visit2    |visit3    |time_visit1_to_visit2|time_visit2_to_visit3|age|\n",
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+---+\n",
            "|Mohammed  |Alfasy   |1987-04-08|2016-01-07|2017-02-03|2018-03-02|393                  |392                  |37 |\n",
            "|Marcy     |Wellmaker|1986-04-08|2015-01-07|2017-01-03|2018-01-02|727                  |364                  |38 |\n",
            "|Ginny     |Ginger   |1986-07-10|2014-08-07|2015-02-03|2016-03-02|180                  |393                  |38 |\n",
            "|Vijay     |Doberson |1988-05-02|2016-01-07|2018-02-03|2018-03-02|758                  |27                   |36 |\n",
            "|Orhan     |Gelicek  |1987-05-11|2016-05-07|2017-01-03|2018-09-02|241                  |607                  |37 |\n",
            "|Sarah     |Jones    |1956-07-06|2016-04-07|2017-08-03|2018-10-02|483                  |425                  |68 |\n",
            "|John      |Johnson  |2017-10-12|2018-01-02|2018-10-03|2018-03-02|274                  |-215                 |7  |\n",
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+---+\n",
            "\n",
            "root\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- last_name: string (nullable = true)\n",
            " |-- dob: date (nullable = true)\n",
            " |-- visit1: date (nullable = true)\n",
            " |-- visit2: date (nullable = true)\n",
            " |-- visit3: date (nullable = true)\n",
            " |-- time_visit1_to_visit2: integer (nullable = true)\n",
            " |-- time_visit2_to_visit3: integer (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Calculate age by subtracting dob from the current date and dividing by 365 (approximately)\n",
        "df = df.withColumn(\"age\", F.floor(F.datediff(F.current_date(), df.dob) / 365))\n",
        "\n",
        "# Show the updated DataFrame\n",
        "df.show(truncate=False)\n",
        "\n",
        "# Check the schema to verify the column types\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu21cDxE-EVn"
      },
      "source": [
        "## 9. Can you extract the month from the first visit column and call it \"Month\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpIlPP6K-EVn",
        "outputId": "91bb49af-78a9-439a-8497-3263f0cfb2ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+---+-----+\n",
            "|first_name|last_name|dob       |visit1    |visit2    |visit3    |time_visit1_to_visit2|time_visit2_to_visit3|age|Month|\n",
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+---+-----+\n",
            "|Mohammed  |Alfasy   |1987-04-08|2016-01-07|2017-02-03|2018-03-02|393                  |392                  |37 |1    |\n",
            "|Marcy     |Wellmaker|1986-04-08|2015-01-07|2017-01-03|2018-01-02|727                  |364                  |38 |1    |\n",
            "|Ginny     |Ginger   |1986-07-10|2014-08-07|2015-02-03|2016-03-02|180                  |393                  |38 |8    |\n",
            "|Vijay     |Doberson |1988-05-02|2016-01-07|2018-02-03|2018-03-02|758                  |27                   |36 |1    |\n",
            "|Orhan     |Gelicek  |1987-05-11|2016-05-07|2017-01-03|2018-09-02|241                  |607                  |37 |5    |\n",
            "|Sarah     |Jones    |1956-07-06|2016-04-07|2017-08-03|2018-10-02|483                  |425                  |68 |4    |\n",
            "|John      |Johnson  |2017-10-12|2018-01-02|2018-10-03|2018-03-02|274                  |-215                 |7  |1    |\n",
            "+----------+---------+----------+----------+----------+----------+---------------------+---------------------+---+-----+\n",
            "\n",
            "root\n",
            " |-- first_name: string (nullable = true)\n",
            " |-- last_name: string (nullable = true)\n",
            " |-- dob: date (nullable = true)\n",
            " |-- visit1: date (nullable = true)\n",
            " |-- visit2: date (nullable = true)\n",
            " |-- visit3: date (nullable = true)\n",
            " |-- time_visit1_to_visit2: integer (nullable = true)\n",
            " |-- time_visit2_to_visit3: integer (nullable = true)\n",
            " |-- age: long (nullable = true)\n",
            " |-- Month: integer (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Extract the month from visit1 and create a new column \"Month\"\n",
        "df = df.withColumn(\"Month\", F.month(\"visit1\"))\n",
        "\n",
        "# Show the updated DataFrame\n",
        "df.show(truncate=False)\n",
        "\n",
        "# Check the schema to verify the column types\n",
        "df.printSchema()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EbKHiPO-EVn"
      },
      "source": [
        "## 10. Challenges with working with date and timestamps\n",
        "\n",
        "Let's read in the supermarket sales dataframe attached to the lecture now and see some of the issues that can come up when working with date and timestamps values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HehvXcCl-EVn",
        "outputId": "d36b8d2a-b4bb-4a93-9ab2-e3cc114122be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-------------------+-----------+------+-----------------------+------------+------+\n",
            "| Invoice ID|Branch|     City|Customer type|Gender|        Product line|Unit price|Quantity| Tax 5%|   Total|     Date|               Time|    Payment|  cogs|gross margin percentage|gross income|Rating|\n",
            "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-------------------+-----------+------+-----------------------+------------+------+\n",
            "|750-67-8428|     A|   Yangon|       Member|Female|   Health and beauty|     74.69|       7|26.1415|548.9715| 1/5/2019|2024-11-07 13:08:00|    Ewallet|522.83|            4.761904762|     26.1415|   9.1|\n",
            "|226-31-3081|     C|Naypyitaw|       Normal|Female|Electronic access...|     15.28|       5|   3.82|   80.22| 3/8/2019|2024-11-07 10:29:00|       Cash|  76.4|            4.761904762|        3.82|   9.6|\n",
            "|631-41-3108|     A|   Yangon|       Normal|  Male|  Home and lifestyle|     46.33|       7|16.2155|340.5255| 3/3/2019|2024-11-07 13:23:00|Credit card|324.31|            4.761904762|     16.2155|   7.4|\n",
            "|123-19-1176|     A|   Yangon|       Member|  Male|   Health and beauty|     58.22|       8| 23.288| 489.048|1/27/2019|2024-11-07 20:33:00|    Ewallet|465.76|            4.761904762|      23.288|   8.4|\n",
            "|373-73-7910|     A|   Yangon|       Normal|  Male|   Sports and travel|     86.31|       7|30.2085|634.3785| 2/8/2019|2024-11-07 10:37:00|    Ewallet|604.17|            4.761904762|     30.2085|   5.3|\n",
            "+-----------+------+---------+-------------+------+--------------------+----------+--------+-------+--------+---------+-------------------+-----------+------+-----------------------+------------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "file_path = './pyspark2/supermarket_sales.csv'\n",
        "market = spark.read.csv(file_path, inferSchema=True, header=True)\n",
        "market.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY0o4wxW-EVn"
      },
      "source": [
        "## About this dataset\n",
        "\n",
        "The growth of supermarkets in most populated cities are increasing and market competitions are also high. The dataset is one of the historical sales of supermarket company which has recorded in 3 different branches for 3 months data.\n",
        "\n",
        " - Attribute information\n",
        " - Invoice id: Computer generated sales slip invoice identification number\n",
        " - Branch: Branch of supercenter (3 branches are available identified by A, B and C).\n",
        " - City: Location of supercenters\n",
        " - Customer type: Type of customers, recorded by Members for customers using member card and Normal for without member card.\n",
        " - Gender: Gender type of customer\n",
        " - Product line: General item categorization groups - Electronic accessories, Fashion accessories, Food and beverages, Health and beauty, Home and lifestyle, Sports and travel\n",
        " - Unit price: Price of each product in USD\n",
        " - Quantity: Number of products purchased by customer\n",
        " - Tax: 5% tax fee for customer buying\n",
        " - Total: Total price including tax\n",
        " - Date: Date of purchase (Record available from January 2019 to March 2019)\n",
        " - Time: Purchase time (10am to 9pm)\n",
        " - Payment: Payment used by customer for purchase (3 methods are available – Cash, Credit card and Ewallet)\n",
        " - COGS: Cost of goods sold\n",
        " - Gross margin percentage: Gross margin percentage\n",
        " - Gross income: Gross income\n",
        " - Rating: Customer stratification rating on their overall shopping experience (On a scale of 1 to 10)\n",
        "\n",
        "**Source:** https://www.kaggle.com/aungpyaeap/supermarket-sales"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zogEpDje-EVn"
      },
      "source": [
        "### View dataframe and schema as usual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqel78mM-EVn",
        "outputId": "9af93355-14cd-4a40-916a-3c26d10a528f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Invoice ID: string (nullable = true)\n",
            " |-- Branch: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Customer type: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Product line: string (nullable = true)\n",
            " |-- Unit price: double (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Tax 5%: double (nullable = true)\n",
            " |-- Total: double (nullable = true)\n",
            " |-- Date: string (nullable = true)\n",
            " |-- Time: timestamp (nullable = true)\n",
            " |-- Payment: string (nullable = true)\n",
            " |-- cogs: double (nullable = true)\n",
            " |-- gross margin percentage: double (nullable = true)\n",
            " |-- gross income: double (nullable = true)\n",
            " |-- Rating: double (nullable = true)\n",
            "\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(market.printSchema())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWf6AueW-EVo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Thq3OvMJ-EVo"
      },
      "source": [
        "### Convert date field to date type\n",
        "\n",
        "Looks like we need to convert the date field into a date type. Let's go ahead and do that.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GwfIb8s-EVo",
        "outputId": "12527027-9427-4e5d-82d0-1c5af8b371dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+---------+-------------+------+----------------------+----------+--------+-------+--------+----+-------------------+-----------+------+-----------------------+------------+------+\n",
            "|Invoice ID |Branch|City     |Customer type|Gender|Product line          |Unit price|Quantity|Tax 5% |Total   |Date|Time               |Payment    |cogs  |gross margin percentage|gross income|Rating|\n",
            "+-----------+------+---------+-------------+------+----------------------+----------+--------+-------+--------+----+-------------------+-----------+------+-----------------------+------------+------+\n",
            "|750-67-8428|A     |Yangon   |Member       |Female|Health and beauty     |74.69     |7       |26.1415|548.9715|NULL|2024-11-07 13:08:00|Ewallet    |522.83|4.761904762            |26.1415     |9.1   |\n",
            "|226-31-3081|C     |Naypyitaw|Normal       |Female|Electronic accessories|15.28     |5       |3.82   |80.22   |NULL|2024-11-07 10:29:00|Cash       |76.4  |4.761904762            |3.82        |9.6   |\n",
            "|631-41-3108|A     |Yangon   |Normal       |Male  |Home and lifestyle    |46.33     |7       |16.2155|340.5255|NULL|2024-11-07 13:23:00|Credit card|324.31|4.761904762            |16.2155     |7.4   |\n",
            "|123-19-1176|A     |Yangon   |Member       |Male  |Health and beauty     |58.22     |8       |23.288 |489.048 |NULL|2024-11-07 20:33:00|Ewallet    |465.76|4.761904762            |23.288      |8.4   |\n",
            "|373-73-7910|A     |Yangon   |Normal       |Male  |Sports and travel     |86.31     |7       |30.2085|634.3785|NULL|2024-11-07 10:37:00|Ewallet    |604.17|4.761904762            |30.2085     |5.3   |\n",
            "|699-14-3026|C     |Naypyitaw|Normal       |Male  |Electronic accessories|85.39     |7       |29.8865|627.6165|NULL|2024-11-07 18:30:00|Ewallet    |597.73|4.761904762            |29.8865     |4.1   |\n",
            "|355-53-5943|A     |Yangon   |Member       |Female|Electronic accessories|68.84     |6       |20.652 |433.692 |NULL|2024-11-07 14:36:00|Ewallet    |413.04|4.761904762            |20.652      |5.8   |\n",
            "|315-22-5665|C     |Naypyitaw|Normal       |Female|Home and lifestyle    |73.56     |10      |36.78  |772.38  |NULL|2024-11-07 11:38:00|Ewallet    |735.6 |4.761904762            |36.78       |8.0   |\n",
            "|665-32-9167|A     |Yangon   |Member       |Female|Health and beauty     |36.26     |2       |3.626  |76.146  |NULL|2024-11-07 17:15:00|Credit card|72.52 |4.761904762            |3.626       |7.2   |\n",
            "|692-92-5582|B     |Mandalay |Member       |Female|Food and beverages    |54.84     |3       |8.226  |172.746 |NULL|2024-11-07 13:27:00|Credit card|164.52|4.761904762            |8.226       |5.9   |\n",
            "|351-62-0822|B     |Mandalay |Member       |Female|Fashion accessories   |14.48     |4       |2.896  |60.816  |NULL|2024-11-07 18:07:00|Ewallet    |57.92 |4.761904762            |2.896       |4.5   |\n",
            "|529-56-3974|B     |Mandalay |Member       |Male  |Electronic accessories|25.51     |4       |5.102  |107.142 |NULL|2024-11-07 17:03:00|Cash       |102.04|4.761904762            |5.102       |6.8   |\n",
            "|365-64-0515|A     |Yangon   |Normal       |Female|Electronic accessories|46.95     |5       |11.7375|246.4875|NULL|2024-11-07 10:25:00|Ewallet    |234.75|4.761904762            |11.7375     |7.1   |\n",
            "|252-56-2699|A     |Yangon   |Normal       |Male  |Food and beverages    |43.19     |10      |21.595 |453.495 |NULL|2024-11-07 16:48:00|Ewallet    |431.9 |4.761904762            |21.595      |8.2   |\n",
            "|829-34-3910|A     |Yangon   |Normal       |Female|Health and beauty     |71.38     |10      |35.69  |749.49  |NULL|2024-11-07 19:21:00|Cash       |713.8 |4.761904762            |35.69       |5.7   |\n",
            "|299-46-1805|B     |Mandalay |Member       |Female|Sports and travel     |93.72     |6       |28.116 |590.436 |NULL|2024-11-07 16:19:00|Cash       |562.32|4.761904762            |28.116      |4.5   |\n",
            "|656-95-9349|A     |Yangon   |Member       |Female|Health and beauty     |68.93     |7       |24.1255|506.6355|NULL|2024-11-07 11:03:00|Credit card|482.51|4.761904762            |24.1255     |4.6   |\n",
            "|765-26-6951|A     |Yangon   |Normal       |Male  |Sports and travel     |72.61     |6       |21.783 |457.443 |NULL|2024-11-07 10:39:00|Credit card|435.66|4.761904762            |21.783      |6.9   |\n",
            "|329-62-1586|A     |Yangon   |Normal       |Male  |Food and beverages    |54.67     |3       |8.2005 |172.2105|NULL|2024-11-07 18:00:00|Credit card|164.01|4.761904762            |8.2005      |8.6   |\n",
            "|319-50-3348|B     |Mandalay |Normal       |Female|Home and lifestyle    |40.3      |2       |4.03   |84.63   |NULL|2024-11-07 15:30:00|Ewallet    |80.6  |4.761904762            |4.03        |4.4   |\n",
            "+-----------+------+---------+-------------+------+----------------------+----------+--------+-------+--------+----+-------------------+-----------+------+-----------------------+------------+------+\n",
            "only showing top 20 rows\n",
            "\n",
            "root\n",
            " |-- Invoice ID: string (nullable = true)\n",
            " |-- Branch: string (nullable = true)\n",
            " |-- City: string (nullable = true)\n",
            " |-- Customer type: string (nullable = true)\n",
            " |-- Gender: string (nullable = true)\n",
            " |-- Product line: string (nullable = true)\n",
            " |-- Unit price: double (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- Tax 5%: double (nullable = true)\n",
            " |-- Total: double (nullable = true)\n",
            " |-- Date: date (nullable = true)\n",
            " |-- Time: timestamp (nullable = true)\n",
            " |-- Payment: string (nullable = true)\n",
            " |-- cogs: double (nullable = true)\n",
            " |-- gross margin percentage: double (nullable = true)\n",
            " |-- gross income: double (nullable = true)\n",
            " |-- Rating: double (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import StringType\n",
        "\n",
        "market = market.withColumn(\"Date\", F.to_date(\"Date\", \"yyyy-M-d\"))\n",
        "market.show(truncate=False)\n",
        "\n",
        "# Check the schema to verify the column types\n",
        "market.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6n_gU1Zr-EVo"
      },
      "source": [
        "### How can we extract the month value from the date field?\n",
        "\n",
        "If you had trouble converting the date field in the previous question think about a more creative solution to extract the month from that field."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBGEF5Dm-EVo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Snx7GlZs-EVo"
      },
      "source": [
        "## 11.0 Working with Arrays\n",
        "\n",
        "Here is a dataframe of reviews from the movie the Dark Night."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fPSHdO-Z-EVo",
        "outputId": "2a4c380e-9725-4988-df2c-c56e9e0368a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------------------------------------------------------------------------------+\n",
            "|rating|review_txt                                                                            |\n",
            "+------+--------------------------------------------------------------------------------------+\n",
            "|5     |Epic. This is the best movie I have EVER seen                                         |\n",
            "|4     |Pretty good, but I would have liked to seen better special effects                    |\n",
            "|3     |So so. Casting could have been improved                                               |\n",
            "|5     |The most EPIC movie of the year! Casting was awesome. Special effects were so intense.|\n",
            "|4     |Solid but I would have liked to see more of the love story                            |\n",
            "|5     |THE BOMB!!!!!!!                                                                       |\n",
            "+------+--------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import *\n",
        "\n",
        "values = [(5,'Epic. This is the best movie I have EVER seen'), \\\n",
        "          (4,'Pretty good, but I would have liked to seen better special effects'), \\\n",
        "          (3,'So so. Casting could have been improved'), \\\n",
        "          (5,'The most EPIC movie of the year! Casting was awesome. Special effects were so intense.'), \\\n",
        "          (4,'Solid but I would have liked to see more of the love story'), \\\n",
        "          (5,'THE BOMB!!!!!!!')]\n",
        "reviews = spark.createDataFrame(values,['rating', 'review_txt'])\n",
        "\n",
        "reviews.show(6,False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCU8ychB-EVp"
      },
      "source": [
        "## 11.1 Let's see if we can create an array off of the review text column and then derive some meaningful results from it.\n",
        "\n",
        "**But first** we need to clean the rview_txt column to make sure we can get what we need from our analysis later on. So let's do the following:\n",
        "\n",
        "1. Remove all punctuation\n",
        "2. lower case everything\n",
        "3. Remove white space (trim)\n",
        "3. Then finally, split the string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAl5wyX9-EVp",
        "outputId": "a00b1241-3f64-48fc-b63e-69c07a2849a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------------------------------------------------------------------------+\n",
            "|rating|review_txt                                                                         |\n",
            "+------+-----------------------------------------------------------------------------------+\n",
            "|5     |Epic This is the best movie I have EVER seen                                       |\n",
            "|4     |Pretty good but I would have liked to seen better special effects                  |\n",
            "|3     |So so Casting could have been improved                                             |\n",
            "|5     |The most EPIC movie of the year Casting was awesome Special effects were so intense|\n",
            "|4     |Solid but I would have liked to see more of the love story                         |\n",
            "|5     |THE BOMB                                                                           |\n",
            "+------+-----------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Assuming 'tweets' is the DataFrame and 'text_column' is the column from which you want to remove punctuation\n",
        "df =reviews.withColumn(\"review_txt\", F.regexp_replace(\"review_txt\", r\"[^\\w\\s]\", \"\"))\n",
        "\n",
        "# Show the DataFrame to check the results\n",
        "df.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Assuming 'text_column' is the column you want to trim\n",
        "df = df.withColumn(\"review_txt\", F.trim(\"review_txt\"))\n",
        "\n",
        "# Show the DataFrame to check the results\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KEwiFmMX4qn",
        "outputId": "7388ac72-1297-4ad0-df97-3db759c8b620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------------------------------------------------------------------------+\n",
            "|rating|review_txt                                                                         |\n",
            "+------+-----------------------------------------------------------------------------------+\n",
            "|5     |epic this is the best movie i have ever seen                                       |\n",
            "|4     |pretty good but i would have liked to seen better special effects                  |\n",
            "|3     |so so casting could have been improved                                             |\n",
            "|5     |the most epic movie of the year casting was awesome special effects were so intense|\n",
            "|4     |solid but i would have liked to see more of the love story                         |\n",
            "|5     |the bomb                                                                           |\n",
            "+------+-----------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgomG7qg-EVp",
        "outputId": "9687d725-ad5e-42b4-e235-d0cc816d3624"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------------------------------------------------------------------------+\n",
            "|rating|review_txt                                                                         |\n",
            "+------+-----------------------------------------------------------------------------------+\n",
            "|5     |epic this is the best movie i have ever seen                                       |\n",
            "|4     |pretty good but i would have liked to seen better special effects                  |\n",
            "|3     |so so casting could have been improved                                             |\n",
            "|5     |the most epic movie of the year casting was awesome special effects were so intense|\n",
            "|4     |solid but i would have liked to see more of the love story                         |\n",
            "|5     |the bomb                                                                           |\n",
            "+------+-----------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Assuming 'text_column' is the column you want to convert to lowercase\n",
        "df = df.withColumn(\"review_txt\", F.lower(\"review_txt\"))\n",
        "\n",
        "# Show the DataFrame to check the results\n",
        "df.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Assuming 'text_column' is the column you want to split by space (or any other delimiter)\n",
        "df = df.withColumn(\"review_txt \", F.split(\"review_txt\", \" \"))\n",
        "\n",
        "# Show the DataFrame to check the results\n",
        "df.show(truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPFfitZXYL_k",
        "outputId": "75b44235-48d4-4df7-b1aa-3eb958c0d4a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "|rating|review_txt                                                                         |review_txt                                                                                         |\n",
            "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "|5     |epic this is the best movie i have ever seen                                       |[epic, this, is, the, best, movie, i, have, ever, seen]                                            |\n",
            "|4     |pretty good but i would have liked to seen better special effects                  |[pretty, good, but, i, would, have, liked, to, seen, better, special, effects]                     |\n",
            "|3     |so so casting could have been improved                                             |[so, so, casting, could, have, been, improved]                                                     |\n",
            "|5     |the most epic movie of the year casting was awesome special effects were so intense|[the, most, epic, movie, of, the, year, casting, was, awesome, special, effects, were, so, intense]|\n",
            "|4     |solid but i would have liked to see more of the love story                         |[solid, but, i, would, have, liked, to, see, more, of, the, love, story]                           |\n",
            "|5     |the bomb                                                                           |[the, bomb]                                                                                        |\n",
            "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9lvaIHE-EVp"
      },
      "source": [
        "## 11.2 Alright now let's see if we can find which reviews contain the word 'Epic'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hwb6D9u-EVp",
        "outputId": "963aac68-aa5c-4f76-e071-1dedbdd4fd74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "|rating|review_txt                                                                         |review_txt                                                                                         |\n",
            "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "|5     |epic this is the best movie i have ever seen                                       |[epic, this, is, the, best, movie, i, have, ever, seen]                                            |\n",
            "|5     |the most epic movie of the year casting was awesome special effects were so intense|[the, most, epic, movie, of, the, year, casting, was, awesome, special, effects, were, so, intense]|\n",
            "+------+-----------------------------------------------------------------------------------+---------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Assuming 'review_column' is the column containing the reviews\n",
        "df_with_epic = df.filter(F.lower(F.col(\"review_txt\")).contains(\"epic\"))\n",
        "\n",
        "# Show the DataFrame with reviews that contain the word 'epic'\n",
        "df_with_epic.show(truncate=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWRZEU3D-EVp"
      },
      "source": [
        "### That's it! Great Job!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "name": "25manipulating_data_in_dataframes_hw.ipynb",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}